# -*- coding: utf-8 -*-
"""FireSafetyAlarm.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pqIBf49sRazyl-OiWpqdR6UhuaH95aIb
"""

import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

# ML Moldels
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

from sklearn.metrics import accuracy_score

# Importing data
df = pd.read_csv('smoke_detection_iot[1].csv')
df.head()

# renaming some columns for better understanding
df = df.rename(columns={'TVOC[ppb]':'Volatile Organic Compounds ppb','eCO2[ppm]':'Equivalent CO2 ppm'})
df.head()

"""## Feature :	Importance in Fire Detection
Temperature & Humidity:	Helps identify fire-prone conditions.

Volatile Organic Compounds ppb & Eqvi CO2: 	Detects combustion gases, signaling fire presence.

Raw H2 & Ethanol:	Indicates chemical fires or fuel-related fires.

Pressure:	Can be useful in fire spread prediction.

PM1.0, PM2.5, NC0.5, NC1.0, NC2.5:	Detects smoke particles, a direct fire indicator.

Fire Alarm:	Target variable for classification.
"""

# Col 'CNT' , 'Unnamed' and	'UTC' are not required much. Still the time of the year can matter but not that much as other columns does , so let's drop this col
df.drop(['Unnamed: 0','CNT','UTC'],axis=1,inplace=True)

"""Let's check for missing values and desired data type"""

df.info()

"""All values are present and all cols are numerical ( Traget col is categorical 0/1)

## Data distribution

1. Temperature[C]
"""

sns.histplot(df['Temperature[C]'], bins = 50)

"""Valid range of temperature and no need to exclude any data as outlier w.r.t Col Temperature[C]

2. Humidity[%]
"""

sns.histplot(df['Humidity[%]'], bins = 50)

"""Valid range of Humidity and no need to exclude any data as outlier w.r.t Col Humidity[%]

3. Pressure[hPa]
"""

sns.histplot(df['Pressure[hPa]'], bins = 50)

sns.boxplot(df['Pressure[hPa]'])

"""all this pressure gets count in low pressure cat ( Mountainous Areas (Higher Altitude)	800 â€“ 950 hPa) . Also the points which visually looks like outlier are nearly equal to points which are comes in the range of IQR, so no need to remove any data points

4. Volatile Organic Compounds ppb
"""

sns.histplot(df['Volatile Organic Compounds ppb'], bins = 10)

sns.boxplot(df['Volatile Organic Compounds ppb'])

# Calculating Q1, Q3, and IQR for 'Volatile Organic Compounds ppb'
Q1 = df['Volatile Organic Compounds ppb'].quantile(0.25)
Q3 = df['Volatile Organic Compounds ppb'].quantile(0.75)
IQR = Q3 - Q1

# Calculating the upper and lower limits
lower_limit = Q1 - 1.5 * IQR
upper_limit = Q3 + 1.5 * IQR

print(f"Lower Limit: {max(lower_limit,0)}")
print(f"Upper Limit: {upper_limit}")

# Filtering data points where 'Volatile Organic Compounds ppb' is greater than 3000
filtered_df = df[df['Volatile Organic Compounds ppb'] > 3000]
print(f"Number of data points with 'Volatile Organic Compounds ppb' > 3000: {len(filtered_df)}")

filtered_df = filtered_df[filtered_df['Fire Alarm']==1]
print(f"Number of data points with 'Volatile Organic Compounds ppb' > 3000 and 'Fire Alarm' = 1: {len(filtered_df)}")

fire_1 = df[df['Fire Alarm']==1]
print(f"Number of data points with 'Equivalent CO2 ppm' > 600: {len(fire_1)}")

# scatter plot between Fire Alarm and Volatile Organic Compounds ppb
sns.scatterplot(data=df, x='Volatile Organic Compounds ppb', y='Fire Alarm')

"""almost all the data points above 3000 are showing similar behavoiur also this data point counts less than 5% of enitre data set . As we are devloping the model for residensial areas we may not get this kind of high values ( higher values expected to occurs for industrial areas ) we can remove drop this data.

"""

# Dropping rows where Volatile Organic Compounds ppb is more than 3000 ppb
df = df[df['Volatile Organic Compounds ppb'] <= 3000]

"""5. Equivalent CO2 ppm"""

sns.histplot(df['Equivalent CO2 ppm'], bins = 10)

sns.boxplot(df['Equivalent CO2 ppm'])

# IQR limits upper and lower limits
Q1 = df['Equivalent CO2 ppm'].quantile(0.25)
Q3 = df['Equivalent CO2 ppm'].quantile(0.75)
IQR = Q3 - Q1

lower_limit = Q1 - 1.5 * IQR
upper_limit = Q3 + 1.5 * IQR

print(f"Lower Limit: {max(lower_limit,0)}")
print(f"Upper Limit: {upper_limit}")

# Filtering data points where 'Equivalent CO2 ppm' is greater than 600 and also how many of them have 'Fire Alarm' = 1
filtered_df = df[df['Equivalent CO2 ppm'] > 600]
print(f"Number of data points with 'Equivalent CO2 ppm' > 600: {len(filtered_df)}")

filtered_df = filtered_df[filtered_df['Fire Alarm']==1]
print(f"Number of data points with 'Equivalent CO2 ppm' > 600 and 'Fire Alarm' = 1: {len(filtered_df)}")

"""for 600+ ppm of CO2 there can be  mild ventilation issues
2000+ ppm of CO2 indicates possible combustion , this is clearly visible in this result
"""

# lets replace all the data points whoes value is > 1000 to 1000
df['Equivalent CO2 ppm'] = df['Equivalent CO2 ppm'].apply(lambda x: 1000 if x > 1000 else x)

# We need the concentration of Particulate Matter , where there exact size will not affect the overall result as it will by there concentrations ,
# so let's remove col 'PM1.0' &	'PM2.5'
df.drop(['PM1.0','PM2.5'],axis=1,inplace=True)

df.head()

df.describe()

"""6. NC0.5 , NC1.0 and NC2.5"""

# Defining function which will give upper and lower limt of IQR and nuber of row above the upper limit
def iqr_outliers(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_limit = Q1 - 1.5 * IQR
    upper_limit = Q3 + 1.5 * IQR
    outliers_count = len(df[df[column] > upper_limit])
    return max(0,lower_limit), upper_limit, outliers_count

sns.histplot(df['NC0.5'], bins = 10)

sns.boxplot(df['NC0.5'])

iqr_outliers(df,'NC0.5')

# limiting max value of NC0.5 to 22
df['NC0.5'] = df['NC0.5'].apply(lambda x: 22 if x > 22 else x)

sns.histplot(df['NC1.0'], bins = 10)

sns.boxplot(df['NC1.0'],color='blue')

iqr_outliers(df,'NC1.0')

# Limint/ capping max value to 4
df['NC1.0'] = df['NC1.0'].apply(lambda x: 4 if x > 4 else x)

sns.histplot(df['NC2.5'], bins = 10)

sns.boxplot(df['NC2.5'],color='green')

iqr_outliers(df,'NC2.5')

# Limint/ capping max value to 0.1
df['NC2.5'] = df['NC2.5'].apply(lambda x: 0.1 if x > 0.1 else x)

sns.heatmap(df.corr(),annot=True)

# As raw H2 has not much impact on on fire alarm let's drop this col
df.drop('Raw H2',axis=1,inplace=True)

# Calculating the sum of 'NC0.5', 'NC1.0', and 'NC2.5'
# all this columns are strongly correlated with each other and can be represnted together ( sum or average)
df['NC_sum'] = df['NC0.5'] + df['NC1.0'] + df['NC2.5']

#dropping NC0.5	NC1.0	NC2.5
df.drop(['NC0.5','NC1.0','NC2.5'],axis=1,inplace=True)

df.describe()

sns.heatmap(df.corr(),annot=True)

"""# Train_Test_Split"""

# lets split the data into train test slpit
X_train, X_test, y_train, y_test = train_test_split(df.drop('Fire Alarm', axis=1), df['Fire Alarm'], test_size=0.2, random_state=42)

X_train.head()

"""# We will create a pipeline for Imputation and scaling"""

# Creating the Imputer
Imputer = ColumnTransformer(
    transformers=[
        ('Imputer', SimpleImputer(strategy="mean"), [0,3,5])
    ],remainder='passthrough')
# Temperature[C], Equivalent CO2 ppm, Pressure[hPa] this parameters are less (<0.3) correlated with Out Put columns

# Creating StandardScaler for col transformation
scaler = ColumnTransformer(
    transformers=[
        ('scaler', StandardScaler(), [0,1,2,3,4,5,6])
    ],remainder='passthrough')

pipe = Pipeline([
    ('Imputer', Imputer),
    ('scaler', scaler)
])

# Imputing and scaling data using object pipe
X_train = pipe.fit_transform(X_train)
X_test = pipe.transform(X_test)

# converting it to Data Frame
X_train = pd.DataFrame(X_train, columns=['Temperature[C]', 'Humidity[%]',  'Volatile Organic Compounds ppb', 'Equivalent CO2 ppm', 'Raw Ethanol','Pressure[hPa]', 'NC_sum' ])
X_test = pd.DataFrame(X_test, columns=['Temperature[C]', 'Humidity[%]',  'Volatile Organic Compounds ppb', 'Equivalent CO2 ppm', 'Raw Ethanol','Pressure[hPa]', 'NC_sum' ])

"""Testing diffrent models"""

lr = LogisticRegression()
dt = DecisionTreeClassifier()
rf = RandomForestClassifier()
svm = SVC()

lr.fit(X_train,y_train)
dt.fit(X_train,y_train)
rf.fit(X_train,y_train)
svm.fit(X_train,y_train)

prediction_lr_train = lr.predict(X_train)
prediction_dt_train = dt.predict(X_train)
prediction_rf_train = rf.predict(X_train)
prediction_svm_train = svm.predict(X_train)

prediction_lr_test = lr.predict(X_test)
prediction_dt_test = dt.predict(X_test)
prediction_rf_test = rf.predict(X_test)
prediction_svm_test = svm.predict(X_test)

score_lr_train = accuracy_score(y_train,prediction_lr_train)
score_dt_train = accuracy_score(y_train,prediction_dt_train)
score_rf_train = accuracy_score(y_train,prediction_rf_train)
score_svm_train = accuracy_score(y_train,prediction_svm_train)

score_dt_test = accuracy_score(y_test,prediction_dt_test)
score_lr_test = accuracy_score(y_test,prediction_lr_test)
score_svm_test = accuracy_score(y_test,prediction_svm_test)
score_rf_test = accuracy_score(y_test,prediction_rf_test)

print(f"Logistic Regression Train Accuracy: {score_lr_train}")
print(f"Decision Tree Train Accuracy: {score_dt_train}")
print(f"Random Forest Train Accuracy: {score_rf_train}")
print(f"Support Vector Machine Train Accuracy: {score_svm_train}")

print(f"Logistic Regression Test Accuracy: {score_lr_test}")
print(f"Decision Tree Test Accuracy: {score_dt_test}")
print(f"Random Forest Test Accuracy: {score_rf_test}")
print(f"Support Vector Machine Test Accuracy: {score_svm_test}")

"""Here SVM, Random Forest and Decision Tree are the two best performing models. As Random Forest is more expensive and SVM consume requires more storage, we can carry forword with Decision Tree"""

model = DecisionTreeClassifier()

pipe_2 = Pipeline([
    ('Imputer', Imputer),
    ('scaler', scaler),
    ('model', model)
])

# using pipe_2
pipe_2.fit(X_train,y_train)
predictions = pipe_2.predict(X_test)
score = accuracy_score(y_test,predictions)
print(f"Test Accuracy: {score}")

# Dumping to pikle file
import pickle

filename = 'finalized_model.sav'
pickle.dump(pipe_2, open(filename, 'wb'))